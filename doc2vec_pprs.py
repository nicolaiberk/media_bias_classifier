# -*- coding: utf-8 -*-
"""hackingCommScience_MediaBias.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G0w43QhPHOoXmZbXWFyIFEg-34J9rbJ1

Code from https://thinkinfi.com/gensim-doc2vec-python-implementation/
"""

from google.colab import drive
drive.mount('/content/drive')

import gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize

import pandas as pd
import numpy as np

pprs = pd.read_csv("https://www.dropbox.com/s/lqqph32xdxr6pfw/germanyPPRs.csv?dl=1", encoding = "UTF-8", encoding_errors="replace")

pprs = pprs[["date", "text", "label"]]

# Tokenization of each document
pprs = pprs.dropna()
pprs = pprs.reset_index()

doc = pprs.text

tokenized_doc = []
for d in doc:
    tokenized_doc.append(word_tokenize(d.lower()))

# Convert tokenized document into gensim formated tagged data
tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]

## Train doc2vec model
model = Doc2Vec(tagged_data, vector_size=300, window=5, min_count=10, workers=4, epochs = 100)

# Save trained doc2vec model
model.save("drive/MyDrive/bias/test_doc2vec.model")